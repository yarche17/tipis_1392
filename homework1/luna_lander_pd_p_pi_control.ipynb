{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc0f2f0-714a-4a7f-a5c0-5f11e121542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер вектора состояния ОУ:  (8,)\n",
      "Структура управляющего воздействия Box(-1.0, 1.0, (2,), float32)\n",
      "Moviepy - Building video random_luna_lander.mp4.\n",
      "Moviepy - Writing video random_luna_lander.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready random_luna_lander.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pid(state, params):\n",
    "    \"\"\"\n",
    "    расчет управляющего воздействия на основе ПД-регуляторования\n",
    "    :param state: состояния ОУ\n",
    "    :param params: параметры ПД-регуляторов\n",
    "    :return: управляющее воздействие\n",
    "    \"\"\"\n",
    "\n",
    "    # Коэффициенты ПД-регулятора\n",
    "    kp_alt = params[0]  # пропорциональная состовляющая по x\n",
    "    kd_alt = params[1]  # дифференцирующая состовляющая по x\n",
    "    kp_ang = params[2]  # пропорциональная состовляющая по углу\n",
    "    kd_ang = params[3]  # дифференцирующая состовляющая по углу\n",
    "\n",
    "    # расчет целевой переменной\n",
    "    alt_tgt = np.abs(state[0])\n",
    "    ang_tgt = (.25 * np.pi) * (state[0] + state[2])\n",
    "\n",
    "    # расчет ошибки\n",
    "    alt_error = (alt_tgt - state[1])\n",
    "    ang_error = (ang_tgt - state[4])\n",
    "\n",
    "    # Формируем управляющее воздействие ПД-регулятора\n",
    "    alt_adj = kp_alt * alt_error + kd_alt * state[3]\n",
    "    ang_adj = kp_ang * ang_error + kd_ang * state[5]\n",
    "\n",
    "\n",
    "    # Приводим к интервалу (-1,  1)\n",
    "    a = np.array([alt_adj, ang_adj])\n",
    "    a = np.clip(a, -1, +1)\n",
    "\n",
    "    # Если есть точка соприкосновения с землей, то глушим двигатели, никакие действия не пердаем\n",
    "    if state[6] or state[7]:\n",
    "        a[:] = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def start_game(environment, params, video_recorder=False):\n",
    "    \"\"\"\n",
    "    Симуляция\n",
    "    :param environment: среда Gym\n",
    "    :param params: параметры ПД-регулятора\n",
    "    :param video_recorder: объект для записи видео. False - без записи видео\n",
    "    :return: суммарное качество посадки\n",
    "    \"\"\"\n",
    "    state, _ = environment.reset()\n",
    "    done = False\n",
    "    total = 0\n",
    "    while not done:\n",
    "        environment.render()\n",
    "        if video_recorder:\n",
    "            video_recorder.capture_frame()\n",
    "\n",
    "        # случайное действие\n",
    "        # action = env.action_space.sample()\n",
    "\n",
    "        # ПД-регулятор\n",
    "        action = pid(state, params)\n",
    "        state, reward, done, info, _ = environment.step(action)\n",
    "        total += reward\n",
    "\n",
    "        # print(state)  # ‘x’: 10 ‘y’: 6.666 ‘vx’: 5\n",
    "        # ‘vy’: 7.5 ‘angle’: 1 ‘angular velocity’: 2.5\n",
    "\n",
    "        # print(reward, done, info, action)\n",
    "    return total\n",
    "\n",
    "\n",
    "def optimize(params, current_score, env, step):\n",
    "    \"\"\"\n",
    "    Подбор парамтеров\n",
    "    :param params: стартовые параметры\n",
    "    :param current_score: текущее качество посадки\n",
    "    :param env: среда gym\n",
    "    :param step: шаг оптимизации\n",
    "    :return: параметры и качество\n",
    "    \"\"\"\n",
    "\n",
    "    # добавить шум (меньше шума при увеличении n_steps)\n",
    "    test_params = params + np.random.normal(0, 2 / step, size=params.shape)\n",
    "\n",
    "    # тестирование параметров\n",
    "    scores = []\n",
    "    for trial in range(5):\n",
    "        score = start_game(env, test_params)\n",
    "        scores.append(score)\n",
    "    avg = np.mean(scores)\n",
    "\n",
    "    # Обновить параметры, если среднее значение награды\n",
    "    # лучше чем с предыдущими параметрами\n",
    "    if avg > current_score:\n",
    "        return test_params, avg\n",
    "    else:\n",
    "        return params, current_score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'LunarLander-v2'\n",
    "\n",
    "    env = gym.make(env_name,\n",
    "                   render_mode=\"rgb_array\",\n",
    "                   continuous=True)\n",
    "\n",
    "    print('Размер вектора состояния ОУ: ', env.observation_space.shape)\n",
    "    print('Структура управляющего воздействия', env.action_space)\n",
    "\n",
    "    optimize_params = False  # True - если хотим подобрать новые параметры\n",
    "    params_pd = np.array([0.84827712, -1.55060286, -1.82178159, 0.8182234])\n",
    "\n",
    "    if optimize_params:\n",
    "        score = start_game(env, params_pd, video_recorder=False)\n",
    "        for steps in range(100):\n",
    "            params_pd, score = optimize(params_pd, score, env, steps+1)\n",
    "            print(\"Step:\", steps, \"Score:\", score, \"Params:\", params_pd)\n",
    "    else:\n",
    "        vid = VideoRecorder(env, path=f\"random_luna_lander.mp4\")\n",
    "        params_pd = np.array([0.84827712, -1.55060286, -1.82178159, 0.8182234])\n",
    "        score = start_game(env, params_pd, video_recorder=vid)\n",
    "\n",
    "        vid.close()\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a1476b-426e-48c8-86d3-8e43d1cb3476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"random_luna_lander.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"random_luna_lander.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7145b41-41bb-4b9c-bdff-111f2f46b868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер вектора состояния ОУ:  (8,)\n",
      "Структура управляющего воздействия Box(-1.0, 1.0, (2,), float32)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def p_contr(state, params):\n",
    "    \"\"\"\n",
    "    расчет управляющего воздействия на основе ПД-регуляторования\n",
    "    :param state: состояния ОУ\n",
    "    :param params: параметры ПД-регуляторов\n",
    "    :return: управляющее воздействие\n",
    "    \"\"\"\n",
    "\n",
    "    # Коэффициенты П-регулятора\n",
    "    kp_alt = params[0]  # пропорциональная состовляющая по x\n",
    "    kp_ang = params[1]  # пропорциональная состовляющая по углу\n",
    "\n",
    "    # расчет целевой переменной\n",
    "    alt_tgt = np.abs(state[0])\n",
    "    ang_tgt = (.25 * np.pi) * (state[0] + state[2])\n",
    "\n",
    "    # расчет ошибки\n",
    "    alt_error = (alt_tgt - state[1])\n",
    "    ang_error = (ang_tgt - state[4])\n",
    "\n",
    "    # Формируем управляющее воздействие ПД-регулятора\n",
    "    alt_adj = kp_alt * alt_error\n",
    "    ang_adj = kp_ang * ang_error\n",
    "\n",
    "\n",
    "    # Приводим к интервалу (-1,  1)\n",
    "    a = np.array([alt_adj, ang_adj])\n",
    "    a = np.clip(a, -1, +1)\n",
    "\n",
    "    # Если есть точка соприкосновения с землей, то глушим двигатели, никакие действия не пердаем\n",
    "    if state[6] or state[7]:\n",
    "        a[:] = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def start_game(environment, params, video_recorder=False):\n",
    "    \"\"\"\n",
    "    Симуляция\n",
    "    :param environment: среда Gym\n",
    "    :param params: параметры ПД-регулятора\n",
    "    :param video_recorder: объект для записи видео. False - без записи видео\n",
    "    :return: суммарное качество посадки\n",
    "    \"\"\"\n",
    "    state, _ = environment.reset()\n",
    "    done = False\n",
    "    total = 0\n",
    "    while not done:\n",
    "        environment.render()\n",
    "        if video_recorder:\n",
    "            video_recorder.capture_frame()\n",
    "\n",
    "        # случайное действие\n",
    "        # action = env.action_space.sample()\n",
    "\n",
    "        # П-регулятор\n",
    "        action = p_contr(state, params)\n",
    "        state, reward, done, info, _ = environment.step(action)\n",
    "        total += reward\n",
    "\n",
    "        # print(state)  # ‘x’: 10 ‘y’: 6.666 ‘vx’: 5\n",
    "        # ‘vy’: 7.5 ‘angle’: 1 ‘angular velocity’: 2.5\n",
    "\n",
    "        # print(reward, done, info, action)\n",
    "    return total\n",
    "\n",
    "\n",
    "def optimize(params, current_score, env, step):\n",
    "    \"\"\"\n",
    "    Подбор парамтеров\n",
    "    :param params: стартовые параметры\n",
    "    :param current_score: текущее качество посадки\n",
    "    :param env: среда gym\n",
    "    :param step: шаг оптимизации\n",
    "    :return: параметры и качество\n",
    "    \"\"\"\n",
    "\n",
    "    # добавить шум (меньше шума при увеличении n_steps)\n",
    "    test_params = params + np.random.normal(0, 2 / step, size=params.shape)\n",
    "\n",
    "    # тестирование параметров\n",
    "    scores = []\n",
    "    for trial in range(5):\n",
    "        score = start_game(env, test_params)\n",
    "        scores.append(score)\n",
    "    avg = np.mean(scores)\n",
    "\n",
    "    # Обновить параметры, если среднее значение награды\n",
    "    # лучше чем с предыдущими параметрами\n",
    "    if avg > current_score:\n",
    "        return test_params, avg\n",
    "    else:\n",
    "        return params, current_score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'LunarLander-v2'\n",
    "\n",
    "    env = gym.make(env_name,\n",
    "                   render_mode=\"rgb_array\",\n",
    "                   continuous=True)\n",
    "\n",
    "    print('Размер вектора состояния ОУ: ', env.observation_space.shape)\n",
    "    print('Структура управляющего воздействия', env.action_space)\n",
    "\n",
    "    optimize_params = True  # True - если хотим подобрать новые параметры\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e91a93e-718f-48d8-aac0-2ee799d733e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3325225933.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    if optimize_params:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "params_pd = np.array([0.84827712, -1.55060286, -1.82178159, 0.8182234])\n",
    "\n",
    "    if optimize_params:\n",
    "        score = start_game(env, params_pd, video_recorder=False)\n",
    "        for steps in range(100):\n",
    "            params_pd, score = optimize(params_pd, score, env, steps+1)\n",
    "            print(\"Step:\", steps, \"Score:\", score, \"Params:\", params_pd)\n",
    "    else:\n",
    "        vid = VideoRecorder(env, path=f\"random_luna_lander.mp4\")\n",
    "        params_pd = np.array([0.84827712, -1.55060286, -1.82178159, 0.8182234])\n",
    "        score = start_game(env, params_pd, video_recorder=vid)\n",
    "\n",
    "        vid.close()\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1019640-72e6-453d-b511-0e48d3158379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер вектора состояния ОУ:  (8,)\n",
      "Структура управляющего воздействия Box(-1.0, 1.0, (2,), float32)\n",
      "Step: 0 Score: -120.52177923478257 Params: [ 0.00366019  0.24644783 -0.09060342 -3.02377614]\n",
      "Step: 1 Score: -120.52177923478257 Params: [ 0.00366019  0.24644783 -0.09060342 -3.02377614]\n",
      "Step: 2 Score: -120.52177923478257 Params: [ 0.00366019  0.24644783 -0.09060342 -3.02377614]\n",
      "Step: 3 Score: -120.52177923478257 Params: [ 0.00366019  0.24644783 -0.09060342 -3.02377614]\n",
      "Step: 4 Score: -120.52177923478257 Params: [ 0.00366019  0.24644783 -0.09060342 -3.02377614]\n",
      "Step: 5 Score: -115.27087520193152 Params: [ 0.1175747  -0.38733318  0.11433632 -3.07145412]\n",
      "Step: 6 Score: -115.27087520193152 Params: [ 0.1175747  -0.38733318  0.11433632 -3.07145412]\n",
      "Step: 7 Score: -107.31926331892282 Params: [ 0.43000593 -0.78999189  0.34666297 -3.26909794]\n",
      "Step: 8 Score: -107.31926331892282 Params: [ 0.43000593 -0.78999189  0.34666297 -3.26909794]\n",
      "Step: 9 Score: -107.31926331892282 Params: [ 0.43000593 -0.78999189  0.34666297 -3.26909794]\n",
      "Step: 10 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 11 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 12 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 13 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 14 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 15 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 16 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 17 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 18 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 19 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 20 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 21 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 22 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 23 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 24 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 25 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 26 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 27 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 28 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 29 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 30 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 31 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 32 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 33 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 34 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 35 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 36 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 37 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 38 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 39 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 40 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 41 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 42 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 43 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 44 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 45 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 46 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 47 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 48 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 49 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 50 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 51 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 52 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 53 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 54 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 55 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 56 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 57 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 58 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 59 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 60 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 61 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 62 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 63 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 64 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 65 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 66 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 67 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 68 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 69 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 70 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 71 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 72 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 73 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 74 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 75 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 76 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 77 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 78 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 79 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 80 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 81 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 82 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 83 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 84 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 85 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 86 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 87 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 88 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 89 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 90 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 91 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 92 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 93 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 94 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 95 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 96 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 97 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 98 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n",
      "Step: 99 Score: -102.39313192805503 Params: [ 0.33426013 -0.70712063  0.3982278  -3.14493256]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def p_contr(state, params):\n",
    "    \"\"\"\n",
    "    расчет управляющего воздействия на основе ПД-регуляторования\n",
    "    :param state: состояния ОУ\n",
    "    :param params: параметры ПД-регуляторов\n",
    "    :return: управляющее воздействие\n",
    "    \"\"\"\n",
    "\n",
    "    # Коэффициенты П-регулятора\n",
    "    kp_alt = params[0]  # пропорциональная состовляющая по x\n",
    "    kp_ang = params[1]  # пропорциональная состовляющая по углу\n",
    "\n",
    "    # расчет целевой переменной\n",
    "    alt_tgt = np.abs(state[0])\n",
    "    ang_tgt = (.25 * np.pi) * (state[0] + state[2])\n",
    "\n",
    "    # расчет ошибки\n",
    "    alt_error = (alt_tgt - state[1])\n",
    "    ang_error = (ang_tgt - state[4])\n",
    "\n",
    "    # Формируем управляющее воздействие ПД-регулятора\n",
    "    alt_adj = kp_alt * alt_error\n",
    "    ang_adj = kp_ang * ang_error\n",
    "\n",
    "\n",
    "    # Приводим к интервалу (-1,  1)\n",
    "    a = np.array([alt_adj, ang_adj])\n",
    "    a = np.clip(a, -1, +1)\n",
    "\n",
    "    # Если есть точка соприкосновения с землей, то глушим двигатели, никакие действия не пердаем\n",
    "    if state[6] or state[7]:\n",
    "        a[:] = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def start_game(environment, params, video_recorder=False):\n",
    "    \"\"\"\n",
    "    Симуляция\n",
    "    :param environment: среда Gym\n",
    "    :param params: параметры ПД-регулятора\n",
    "    :param video_recorder: объект для записи видео. False - без записи видео\n",
    "    :return: суммарное качество посадки\n",
    "    \"\"\"\n",
    "    state, _ = environment.reset()\n",
    "    done = False\n",
    "    total = 0\n",
    "    while not done:\n",
    "        environment.render()\n",
    "        if video_recorder:\n",
    "            video_recorder.capture_frame()\n",
    "\n",
    "        # случайное действие\n",
    "        # action = env.action_space.sample()\n",
    "\n",
    "        # П-регулятор\n",
    "        action = p_contr(state, params)\n",
    "        state, reward, done, info, _ = environment.step(action)\n",
    "        total += reward\n",
    "\n",
    "        # print(state)  # ‘x’: 10 ‘y’: 6.666 ‘vx’: 5\n",
    "        # ‘vy’: 7.5 ‘angle’: 1 ‘angular velocity’: 2.5\n",
    "\n",
    "        # print(reward, done, info, action)\n",
    "    return total\n",
    "\n",
    "\n",
    "def optimize(params, current_score, env, step):\n",
    "    \"\"\"\n",
    "    Подбор парамтеров\n",
    "    :param params: стартовые параметры\n",
    "    :param current_score: текущее качество посадки\n",
    "    :param env: среда gym\n",
    "    :param step: шаг оптимизации\n",
    "    :return: параметры и качество\n",
    "    \"\"\"\n",
    "\n",
    "    # добавить шум (меньше шума при увеличении n_steps)\n",
    "    test_params = params + np.random.normal(0, 2 / step, size=params.shape)\n",
    "\n",
    "    # тестирование параметров\n",
    "    scores = []\n",
    "    for trial in range(5):\n",
    "        score = start_game(env, test_params)\n",
    "        scores.append(score)\n",
    "    avg = np.mean(scores)\n",
    "\n",
    "    # Обновить параметры, если среднее значение награды\n",
    "    # лучше чем с предыдущими параметрами\n",
    "    if avg > current_score:\n",
    "        return test_params, avg\n",
    "    else:\n",
    "        return params, current_score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'LunarLander-v2'\n",
    "\n",
    "    env = gym.make(env_name,\n",
    "                   render_mode=\"rgb_array\",\n",
    "                   continuous=True)\n",
    "\n",
    "    print('Размер вектора состояния ОУ: ', env.observation_space.shape)\n",
    "    print('Структура управляющего воздействия', env.action_space)\n",
    "\n",
    "    optimize_params = True  # True - если хотим подобрать новые параметры\n",
    "    params_pd = np.array([0.84827712, -1.55060286, -1.82178159, 0.8182234])\n",
    "\n",
    "    if optimize_params:\n",
    "        score = start_game(env, params_pd, video_recorder=False)\n",
    "        for steps in range(100):\n",
    "            params_pd, score = optimize(params_pd, score, env, steps+1)\n",
    "            print(\"Step:\", steps, \"Score:\", score, \"Params:\", params_pd)\n",
    "    else:\n",
    "        vid = VideoRecorder(env, path=f\"random_luna_lander.mp4\")\n",
    "        params_pd = np.array([0.84827712, -1.55060286, -1.82178159, 0.8182234])\n",
    "        score = start_game(env, params_pd, video_recorder=vid)\n",
    "\n",
    "        vid.close()\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "523f3b9a-f914-4ead-aefa-53c0c4baa6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер вектора состояния ОУ:  (8,)\n",
      "Структура управляющего воздействия Box(-1.0, 1.0, (2,), float32)\n",
      "Moviepy - Building video random_luna_lander.mp4.\n",
      "Moviepy - Writing video random_luna_lander.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready random_luna_lander.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def p_contr(state, params):\n",
    "    \"\"\"\n",
    "    расчет управляющего воздействия на основе ПД-регуляторования\n",
    "    :param state: состояния ОУ\n",
    "    :param params: параметры ПД-регуляторов\n",
    "    :return: управляющее воздействие\n",
    "    \"\"\"\n",
    "\n",
    "    # Коэффициенты П-регулятора\n",
    "    kp_alt = params[0]  # пропорциональная состовляющая по x\n",
    "    kp_ang = params[1]  # пропорциональная состовляющая по углу\n",
    "\n",
    "    # расчет целевой переменной\n",
    "    alt_tgt = np.abs(state[0])\n",
    "    ang_tgt = (.25 * np.pi) * (state[0] + state[2])\n",
    "\n",
    "    # расчет ошибки\n",
    "    alt_error = (alt_tgt - state[1])\n",
    "    ang_error = (ang_tgt - state[4])\n",
    "\n",
    "    # Формируем управляющее воздействие П-регулятора\n",
    "    alt_adj = kp_alt * alt_error\n",
    "    ang_adj = kp_ang * ang_error\n",
    "\n",
    "\n",
    "    # Приводим к интервалу (-1,  1)\n",
    "    a = np.array([alt_adj, ang_adj])\n",
    "    a = np.clip(a, -1, +1)\n",
    "\n",
    "    # Если есть точка соприкосновения с землей, то глушим двигатели, никакие действия не пердаем\n",
    "    if state[6] or state[7]:\n",
    "        a[:] = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def start_game(environment, params, video_recorder=False):\n",
    "    \"\"\"\n",
    "    Симуляция\n",
    "    :param environment: среда Gym\n",
    "    :param params: параметры ПД-регулятора\n",
    "    :param video_recorder: объект для записи видео. False - без записи видео\n",
    "    :return: суммарное качество посадки\n",
    "    \"\"\"\n",
    "    state, _ = environment.reset()\n",
    "    done = False\n",
    "    total = 0\n",
    "    while not done:\n",
    "        environment.render()\n",
    "        if video_recorder:\n",
    "            video_recorder.capture_frame()\n",
    "\n",
    "        # случайное действие\n",
    "        # action = env.action_space.sample()\n",
    "\n",
    "        # П-регулятор\n",
    "        action = p_contr(state, params)\n",
    "        state, reward, done, info, _ = environment.step(action)\n",
    "        total += reward\n",
    "\n",
    "        # print(state)  # ‘x’: 10 ‘y’: 6.666 ‘vx’: 5\n",
    "        # ‘vy’: 7.5 ‘angle’: 1 ‘angular velocity’: 2.5\n",
    "\n",
    "        # print(reward, done, info, action)\n",
    "    return total\n",
    "\n",
    "\n",
    "def optimize(params, current_score, env, step):\n",
    "    \"\"\"\n",
    "    Подбор парамтеров\n",
    "    :param params: стартовые параметры\n",
    "    :param current_score: текущее качество посадки\n",
    "    :param env: среда gym\n",
    "    :param step: шаг оптимизации\n",
    "    :return: параметры и качество\n",
    "    \"\"\"\n",
    "\n",
    "    # добавить шум (меньше шума при увеличении n_steps)\n",
    "    test_params = params + np.random.normal(0, 2 / step, size=params.shape)\n",
    "\n",
    "    # тестирование параметров\n",
    "    scores = []\n",
    "    for trial in range(5):\n",
    "        score = start_game(env, test_params)\n",
    "        scores.append(score)\n",
    "    avg = np.mean(scores)\n",
    "\n",
    "    # Обновить параметры, если среднее значение награды\n",
    "    # лучше чем с предыдущими параметрами\n",
    "    if avg > current_score:\n",
    "        return test_params, avg\n",
    "    else:\n",
    "        return params, current_score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'LunarLander-v2'\n",
    "\n",
    "    env = gym.make(env_name,\n",
    "                   render_mode=\"rgb_array\",\n",
    "                   continuous=True)\n",
    "\n",
    "    print('Размер вектора состояния ОУ: ', env.observation_space.shape)\n",
    "    print('Структура управляющего воздействия', env.action_space)\n",
    "\n",
    "    optimize_params = False  # True - если хотим подобрать новые параметры\n",
    "    params_pd = np.array([0.52884285, -0.57335351, 0.50929118, -3.27601328])\n",
    "\n",
    "    if optimize_params:\n",
    "        score = start_game(env, params_pd, video_recorder=False)\n",
    "        for steps in range(100):\n",
    "            params_pd, score = optimize(params_pd, score, env, steps+1)\n",
    "            print(\"Step:\", steps, \"Score:\", score, \"Params:\", params_pd)\n",
    "    else:\n",
    "        vid = VideoRecorder(env, path=f\"random_luna_lander.mp4\")\n",
    "        params_pd = np.array([0.52884285, -0.57335351, 0.50929118, -3.27601328])\n",
    "        score = start_game(env, params_pd, video_recorder=vid)\n",
    "\n",
    "        vid.close()\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dc6f136-2435-4c3f-971f-890b5e83b1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"random_luna_lander.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"random_luna_lander.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ae8647-db5a-4317-bda4-8c06c59102b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер вектора состояния ОУ:  (8,)\n",
      "Структура управляющего воздействия Box(-1.0, 1.0, (2,), float32)\n",
      "Moviepy - Building video random_luna_lander.mp4.\n",
      "Moviepy - Writing video random_luna_lander.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready random_luna_lander.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pi(state, params):\n",
    "    \"\"\"\n",
    "    расчет управляющего воздействия на основе ПД-регуляторования\n",
    "    :param state: состояния ОУ\n",
    "    :param params: параметры ПИ-регуляторов\n",
    "    :return: управляющее воздействие\n",
    "    \"\"\"\n",
    "\n",
    "    # Коэффициенты ПИ-регулятора\n",
    "    kp_alt = params[0]  # пропорциональная состовляющая по x\n",
    "    ki_alt = params[1] \n",
    "    kp_ang = params[2]  # пропорциональная состовляющая по углу\n",
    "    ki_ang = params[3]\n",
    "    \n",
    "    # расчет целевой переменной\n",
    "    alt_tgt = np.abs(state[0])\n",
    "    ang_tgt = (.25 * np.pi) * (state[0] + state[2])\n",
    "\n",
    "    # расчет ошибки\n",
    "    alt_error = (alt_tgt - state[1])\n",
    "    ang_error = (ang_tgt - state[4])\n",
    "\n",
    "    # Формируем управляющее воздействие ПИ-регулятора\n",
    "    alt_adj = kp_alt * alt_error + ki_alt * np.sum(alt_error)\n",
    "    ang_adj = kp_ang * ang_error + ki_ang * np.sum(ang_error)\n",
    "\n",
    "\n",
    "    # Приводим к интервалу (-1,  1)\n",
    "    a = np.array([alt_adj, ang_adj])\n",
    "    a = np.clip(a, -1, +1)\n",
    "\n",
    "    # Если есть точка соприкосновения с землей, то глушим двигатели, никакие действия не пердаем\n",
    "    if state[6] or state[7]:\n",
    "        a[:] = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def start_game(environment, params, video_recorder=False):\n",
    "    \"\"\"\n",
    "    Симуляция\n",
    "    :param environment: среда Gym\n",
    "    :param params: параметры ПИ-регулятора\n",
    "    :param video_recorder: объект для записи видео. False - без записи видео\n",
    "    :return: суммарное качество посадки\n",
    "    \"\"\"\n",
    "    state, _ = environment.reset()\n",
    "    done = False\n",
    "    total = 0\n",
    "    while not done:\n",
    "        environment.render()\n",
    "        if video_recorder:\n",
    "            video_recorder.capture_frame()\n",
    "\n",
    "        # случайное действие\n",
    "        # action = env.action_space.sample()\n",
    "\n",
    "        # ПИ-регулятор\n",
    "        action = pi(state, params)\n",
    "        state, reward, done, info, _ = environment.step(action)\n",
    "        total += reward\n",
    "\n",
    "        # print(state)  # ‘x’: 10 ‘y’: 6.666 ‘vx’: 5\n",
    "        # ‘vy’: 7.5 ‘angle’: 1 ‘angular velocity’: 2.5\n",
    "\n",
    "        # print(reward, done, info, action)\n",
    "    return total\n",
    "\n",
    "\n",
    "def optimize(params, current_score, env, step):\n",
    "    \"\"\"\n",
    "    Подбор парамтеров\n",
    "    :param params: стартовые параметры\n",
    "    :param current_score: текущее качество посадки\n",
    "    :param env: среда gym\n",
    "    :param step: шаг оптимизации\n",
    "    :return: параметры и качество\n",
    "    \"\"\"\n",
    "\n",
    "    # добавить шум (меньше шума при увеличении n_steps)\n",
    "    test_params = params + np.random.normal(0, 2 / step, size=params.shape)\n",
    "\n",
    "    # тестирование параметров\n",
    "    scores = []\n",
    "    for trial in range(5):\n",
    "        score = start_game(env, test_params)\n",
    "        scores.append(score)\n",
    "    avg = np.mean(scores)\n",
    "\n",
    "    # Обновить параметры, если среднее значение награды\n",
    "    # лучше чем с предыдущими параметрами\n",
    "    if avg > current_score:\n",
    "        return test_params, avg\n",
    "    else:\n",
    "        return params, current_score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'LunarLander-v2'\n",
    "\n",
    "    env = gym.make(env_name,\n",
    "                   render_mode=\"rgb_array\",\n",
    "                   continuous=True)\n",
    "\n",
    "    print('Размер вектора состояния ОУ: ', env.observation_space.shape)\n",
    "    print('Структура управляющего воздействия', env.action_space)\n",
    "\n",
    "    optimize_params = False # True - если хотим подобрать новые параметры\n",
    "    params_pd = np.array([0.24937654, 1.2451512, 0.61247268, -4.73925231])\n",
    "\n",
    "    if optimize_params:\n",
    "        score = start_game(env, params_pd, video_recorder=False)\n",
    "        for steps in range(100):\n",
    "            params_pd, score = optimize(params_pd, score, env, steps+1)\n",
    "            print(\"Step:\", steps, \"Score:\", score, \"Params:\", params_pd)\n",
    "    else:\n",
    "        vid = VideoRecorder(env, path=f\"random_luna_lander.mp4\")\n",
    "        params_pd = np.array([0.24937654, 1.2451512, 0.61247268, -4.73925231])\n",
    "        score = start_game(env, params_pd, video_recorder=vid)\n",
    "\n",
    "        vid.close()\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a14076b-7680-4380-8a9c-4cd707c3227f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"random_luna_lander.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"random_luna_lander.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12a245-ed0f-4a2a-8c81-725b4fda852d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
